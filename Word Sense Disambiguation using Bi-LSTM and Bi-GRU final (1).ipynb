{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English WSD Preprocessing and train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approach</td>\n",
       "      <td>V</td>\n",
       "      <td>Approach a task.</td>\n",
       "      <td>To approach the city.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summer</td>\n",
       "      <td>V</td>\n",
       "      <td>We like to summer in the Mediterranean.</td>\n",
       "      <td>We summered in Kashmir.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet</td>\n",
       "      <td>V</td>\n",
       "      <td>The company agrees to meet the cost of any rep...</td>\n",
       "      <td>This proposal meets my requirements.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development</td>\n",
       "      <td>N</td>\n",
       "      <td>The organism has reached a crucial stage in it...</td>\n",
       "      <td>Our news team brings you the latest developments.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrowness</td>\n",
       "      <td>N</td>\n",
       "      <td>The problem with achievement tests is the narr...</td>\n",
       "      <td>Frustrated by the narrowness of people's horiz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>round</td>\n",
       "      <td>N</td>\n",
       "      <td>He ordered a second round.</td>\n",
       "      <td>They brought us a round of drinks about every ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>run</td>\n",
       "      <td>N</td>\n",
       "      <td>The team enjoyed a brief run of victories.</td>\n",
       "      <td>Yesterday we did a run of 12,000 units.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>charge</td>\n",
       "      <td>V</td>\n",
       "      <td>Can I charge this purchase?</td>\n",
       "      <td>The suspect was charged with murdering his wife.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>catch</td>\n",
       "      <td>V</td>\n",
       "      <td>Catch one's breath.</td>\n",
       "      <td>I caught the hem of my dress in the brambles.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>rest</td>\n",
       "      <td>N</td>\n",
       "      <td>Now that we're all in agreement, we can put th...</td>\n",
       "      <td>The ocean was finally at rest.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5428 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column1 Column2                                            Column7  \\\n",
       "0        approach       V                                   Approach a task.   \n",
       "1          summer       V            We like to summer in the Mediterranean.   \n",
       "2            meet       V  The company agrees to meet the cost of any rep...   \n",
       "3     development       N  The organism has reached a crucial stage in it...   \n",
       "4      narrowness       N  The problem with achievement tests is the narr...   \n",
       "...           ...     ...                                                ...   \n",
       "5423        round       N                         He ordered a second round.   \n",
       "5424          run       N         The team enjoyed a brief run of victories.   \n",
       "5425       charge       V                        Can I charge this purchase?   \n",
       "5426        catch       V                                Catch one's breath.   \n",
       "5427         rest       N  Now that we're all in agreement, we can put th...   \n",
       "\n",
       "                                                Column8  Column9  \n",
       "0                                 To approach the city.        0  \n",
       "1                               We summered in Kashmir.        1  \n",
       "2                  This proposal meets my requirements.        1  \n",
       "3     Our news team brings you the latest developments.        0  \n",
       "4     Frustrated by the narrowness of people's horiz...        1  \n",
       "...                                                 ...      ...  \n",
       "5423  They brought us a round of drinks about every ...        1  \n",
       "5424            Yesterday we did a run of 12,000 units.        0  \n",
       "5425   The suspect was charged with murdering his wife.        0  \n",
       "5426      I caught the hem of my dress in the brambles.        0  \n",
       "5427                     The ocean was finally at rest.        1  \n",
       "\n",
       "[5428 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"English.csv\")\n",
    "selected_columns = df.iloc[:, [0,1, 6, 7, 8]]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the columns from the DataFrame\n",
    "train_word = df[\"Column1\"].tolist()\n",
    "train_context1 = df[\"Column7\"].astype(str).tolist()\n",
    "train_context2 = df[\"Column8\"].astype(str).tolist()\n",
    "train_label = np.array(df[\"Column9\"].tolist())\n",
    "\n",
    "# Prepare input and output data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_context1 + train_context2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_context1_seq = tokenizer.texts_to_sequences(train_context1)\n",
    "train_context2_seq = tokenizer.texts_to_sequences(train_context2)\n",
    "\n",
    "max_len = 30\n",
    "train_context1_seq = pad_sequences(train_context1_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "train_context2_seq = pad_sequences(train_context2_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "train_input = np.concatenate((train_context1_seq, train_context2_seq), axis=1)\n",
    "\n",
    "num_classes = 2\n",
    "train_output = tf.keras.utils.to_categorical(train_label, num_classes)\n",
    "\n",
    "# Train-validation split\n",
    "train_input, val_input, train_output, val_output = train_test_split(train_input, train_output, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bi-LSTM-English**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 14s 94ms/step - loss: 0.6908 - accuracy: 0.5366 - val_loss: 0.6808 - val_accuracy: 0.5692\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 11s 99ms/step - loss: 0.5814 - accuracy: 0.7016 - val_loss: 0.7197 - val_accuracy: 0.5893\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 13s 113ms/step - loss: 0.4242 - accuracy: 0.8075 - val_loss: 0.7770 - val_accuracy: 0.5960\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 11s 99ms/step - loss: 0.3178 - accuracy: 0.8592 - val_loss: 0.9772 - val_accuracy: 0.5993\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 12s 104ms/step - loss: 0.2524 - accuracy: 0.8853 - val_loss: 0.9623 - val_accuracy: 0.5949\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 12s 103ms/step - loss: 0.2021 - accuracy: 0.9153 - val_loss: 1.1906 - val_accuracy: 0.5871\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 13s 112ms/step - loss: 0.1430 - accuracy: 0.9466 - val_loss: 1.3742 - val_accuracy: 0.5938\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 13s 110ms/step - loss: 0.1031 - accuracy: 0.9620 - val_loss: 1.4627 - val_accuracy: 0.5898\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 12s 108ms/step - loss: 0.0762 - accuracy: 0.9728 - val_loss: 1.7179 - val_accuracy: 0.5988\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 14s 119ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 2.1359 - val_accuracy: 0.5871\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.1359 - accuracy: 0.5871\n",
      "BiLSTM_english Loss  : 2.135896921157837, BiLSTM_english Accuracy: 0.5870535969734192\n"
     ]
    }
   ],
   "source": [
    "# Build the BiLSTM model\n",
    "input_shape = (2 * max_len,)\n",
    "embedding_dim = 64\n",
    "lstm_units = 128\n",
    "\n",
    "BiLSTM_english = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units)),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiLSTM_english.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiLSTM_english.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiLSTM_english_loss, BiLSTM_english_accuracy = BiLSTM_english.evaluate(val_input, val_output)\n",
    "print(f\"BiLSTM_english Loss  : {BiLSTM_english_loss}, BiLSTM_english Accuracy: {BiLSTM_english_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranc\\AppData\\Local\\Temp\\ipykernel_14860\\2253339293.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "76/76 [==============================] - 7s 36ms/step - loss: 0.6939 - accuracy: 0.5054\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.6908 - accuracy: 0.5215\n",
      "76/76 [==============================] - 7s 39ms/step - loss: 0.6933 - accuracy: 0.5062\n",
      "38/38 [==============================] - 2s 15ms/step - loss: 0.6896 - accuracy: 0.5206\n",
      "76/76 [==============================] - 8s 39ms/step - loss: 0.6928 - accuracy: 0.5136\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.6900 - accuracy: 0.5231\n",
      "76/76 [==============================] - 9s 76ms/step - loss: 0.6938 - accuracy: 0.5008\n",
      "38/38 [==============================] - 2s 28ms/step - loss: 0.6893 - accuracy: 0.5528\n",
      "76/76 [==============================] - 9s 78ms/step - loss: 0.6935 - accuracy: 0.5095\n",
      "38/38 [==============================] - 2s 30ms/step - loss: 0.6888 - accuracy: 0.5743\n",
      "76/76 [==============================] - 10s 83ms/step - loss: 0.6915 - accuracy: 0.5078\n",
      "38/38 [==============================] - 2s 34ms/step - loss: 0.6886 - accuracy: 0.5396\n",
      "76/76 [==============================] - 25s 281ms/step - loss: 0.6927 - accuracy: 0.5190\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.6894 - accuracy: 0.5495\n",
      "76/76 [==============================] - 25s 283ms/step - loss: 0.6926 - accuracy: 0.5021\n",
      "38/38 [==============================] - 5s 104ms/step - loss: 0.6890 - accuracy: 0.5330\n",
      "76/76 [==============================] - 28s 318ms/step - loss: 0.6946 - accuracy: 0.4988\n",
      "38/38 [==============================] - 5s 106ms/step - loss: 0.6909 - accuracy: 0.5404\n",
      "76/76 [==============================] - 9s 58ms/step - loss: 0.6929 - accuracy: 0.5182\n",
      "38/38 [==============================] - 2s 22ms/step - loss: 0.6876 - accuracy: 0.5817\n",
      "76/76 [==============================] - 9s 57ms/step - loss: 0.6939 - accuracy: 0.5157\n",
      "38/38 [==============================] - 2s 19ms/step - loss: 0.6868 - accuracy: 0.5652\n",
      "76/76 [==============================] - 9s 61ms/step - loss: 0.6910 - accuracy: 0.5190\n",
      "38/38 [==============================] - 2s 19ms/step - loss: 0.6864 - accuracy: 0.5528\n",
      "76/76 [==============================] - 14s 124ms/step - loss: 0.6920 - accuracy: 0.5367\n",
      "38/38 [==============================] - 3s 44ms/step - loss: 0.6871 - accuracy: 0.5660\n",
      "76/76 [==============================] - 12s 113ms/step - loss: 0.6930 - accuracy: 0.5025\n",
      "38/38 [==============================] - 3s 44ms/step - loss: 0.6867 - accuracy: 0.5792\n",
      "76/76 [==============================] - 12s 112ms/step - loss: 0.6914 - accuracy: 0.5219\n",
      "38/38 [==============================] - 2s 39ms/step - loss: 0.6859 - accuracy: 0.5602\n",
      "76/76 [==============================] - 36s 414ms/step - loss: 0.6919 - accuracy: 0.5318\n",
      "38/38 [==============================] - 6s 122ms/step - loss: 0.6853 - accuracy: 0.5800\n",
      "76/76 [==============================] - 34s 389ms/step - loss: 0.6939 - accuracy: 0.5144\n",
      "38/38 [==============================] - 5s 112ms/step - loss: 0.6900 - accuracy: 0.5157\n",
      "76/76 [==============================] - 34s 387ms/step - loss: 0.6922 - accuracy: 0.5210\n",
      "38/38 [==============================] - 5s 107ms/step - loss: 0.6875 - accuracy: 0.5660\n",
      "76/76 [==============================] - 10s 81ms/step - loss: 0.6931 - accuracy: 0.5235\n",
      "38/38 [==============================] - 2s 26ms/step - loss: 0.6821 - accuracy: 0.5858\n",
      "76/76 [==============================] - 11s 90ms/step - loss: 0.6909 - accuracy: 0.5384\n",
      "38/38 [==============================] - 2s 27ms/step - loss: 0.6827 - accuracy: 0.5578\n",
      "76/76 [==============================] - 10s 77ms/step - loss: 0.6909 - accuracy: 0.5309\n",
      "38/38 [==============================] - 2s 23ms/step - loss: 0.6848 - accuracy: 0.5528\n",
      "76/76 [==============================] - 16s 153ms/step - loss: 0.6921 - accuracy: 0.5392\n",
      "38/38 [==============================] - 3s 53ms/step - loss: 0.6825 - accuracy: 0.5842\n",
      "76/76 [==============================] - 15s 148ms/step - loss: 0.6921 - accuracy: 0.5264\n",
      "38/38 [==============================] - 3s 50ms/step - loss: 0.6833 - accuracy: 0.5701\n",
      "76/76 [==============================] - 15s 148ms/step - loss: 0.6906 - accuracy: 0.5363\n",
      "38/38 [==============================] - 3s 48ms/step - loss: 0.6856 - accuracy: 0.5652\n",
      "76/76 [==============================] - 36s 422ms/step - loss: 0.6917 - accuracy: 0.5190\n",
      "38/38 [==============================] - 5s 117ms/step - loss: 0.6796 - accuracy: 0.5718\n",
      "76/76 [==============================] - 35s 410ms/step - loss: 0.6924 - accuracy: 0.5252\n",
      "38/38 [==============================] - 6s 132ms/step - loss: 0.6844 - accuracy: 0.5660\n",
      "76/76 [==============================] - 34s 397ms/step - loss: 0.6900 - accuracy: 0.5243\n",
      "38/38 [==============================] - 6s 128ms/step - loss: 0.6819 - accuracy: 0.5677\n",
      "114/114 [==============================] - 22s 156ms/step - loss: 0.6870 - accuracy: 0.5407\n",
      "Best parameters:  {'embedding_dim': 128, 'lstm_units': 128}\n",
      "Best accuracy:  0.5731573104858398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'embedding_dim': [32, 64, 128],\n",
    "    'lstm_units': [64, 128, 256],\n",
    "}\n",
    "\n",
    "# Define the model\n",
    "def create_model(embedding_dim, lstm_units):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_shape=input_shape),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units)),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Create the Keras classifier\n",
    "keras_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(create_model)\n",
    "\n",
    "# Create the GridSearchCV instance\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=keras_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(train_input, train_output)\n",
    "\n",
    "# Print the best parameters and results\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best accuracy: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 25s 176ms/step - loss: 1.2759 - accuracy: 0.5044 - val_loss: 0.7150 - val_accuracy: 0.5547\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 19s 170ms/step - loss: 0.6612 - accuracy: 0.6408 - val_loss: 0.6828 - val_accuracy: 0.5893\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 20s 173ms/step - loss: 0.5112 - accuracy: 0.7827 - val_loss: 0.7735 - val_accuracy: 0.5804\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 20s 175ms/step - loss: 0.3880 - accuracy: 0.8391 - val_loss: 0.8642 - val_accuracy: 0.5876\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 20s 173ms/step - loss: 0.3198 - accuracy: 0.8721 - val_loss: 0.9851 - val_accuracy: 0.6004\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 21s 181ms/step - loss: 0.2782 - accuracy: 0.8804 - val_loss: 0.9483 - val_accuracy: 0.5831\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 20s 174ms/step - loss: 0.2568 - accuracy: 0.8892 - val_loss: 1.0720 - val_accuracy: 0.5926\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 20s 174ms/step - loss: 0.2353 - accuracy: 0.8966 - val_loss: 1.2313 - val_accuracy: 0.5921\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 21s 182ms/step - loss: 0.2157 - accuracy: 0.9095 - val_loss: 1.1682 - val_accuracy: 0.5971\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 21s 188ms/step - loss: 0.1824 - accuracy: 0.9329 - val_loss: 1.5250 - val_accuracy: 0.5949\n",
      "56/56 [==============================] - 4s 67ms/step - loss: 1.5250 - accuracy: 0.5949\n",
      "BiLSTM_english Loss: 1.5250314474105835, BiLSTM_english Accuracy: 0.5948660969734192\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Build the BiLSTM model with L2 regularization\n",
    "BiLSTM_english = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, kernel_regularizer=regularizers.l2(0.01))),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiLSTM_english.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiLSTM_english.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiLSTM_english_loss, BiLSTM_english_accuracy = BiLSTM_english.evaluate(val_input, val_output)\n",
    "print(f\"BiLSTM_english Loss: {BiLSTM_english_loss}, BiLSTM_english Accuracy: {BiLSTM_english_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 23s 167ms/step - loss: 6.4805 - accuracy: 0.4989 - val_loss: 0.9119 - val_accuracy: 0.5011\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 18s 159ms/step - loss: 0.7406 - accuracy: 0.5366 - val_loss: 0.7522 - val_accuracy: 0.5223\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 19s 168ms/step - loss: 0.7087 - accuracy: 0.6469 - val_loss: 0.7107 - val_accuracy: 0.5725\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 19s 170ms/step - loss: 0.5873 - accuracy: 0.7305 - val_loss: 0.7117 - val_accuracy: 0.5938\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 19s 163ms/step - loss: 0.4681 - accuracy: 0.8116 - val_loss: 0.7974 - val_accuracy: 0.5798\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 18s 162ms/step - loss: 0.3820 - accuracy: 0.8487 - val_loss: 0.8858 - val_accuracy: 0.6105\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 18s 162ms/step - loss: 0.3192 - accuracy: 0.8804 - val_loss: 0.9748 - val_accuracy: 0.6077\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 18s 161ms/step - loss: 0.2590 - accuracy: 0.9131 - val_loss: 1.0268 - val_accuracy: 0.6133\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 18s 161ms/step - loss: 0.2234 - accuracy: 0.9213 - val_loss: 1.0915 - val_accuracy: 0.6021\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 18s 162ms/step - loss: 0.1921 - accuracy: 0.9359 - val_loss: 1.3468 - val_accuracy: 0.6116\n",
      "56/56 [==============================] - 3s 53ms/step - loss: 1.3468 - accuracy: 0.6116\n",
      "BiLSTM_english Loss: 1.3467786312103271, BiLSTM_english Accuracy: 0.6116071343421936\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Build the BiLSTM model with L2 regularization\n",
    "BiLSTM_english = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, kernel_regularizer=regularizers.l2(0.1))),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiLSTM_english.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiLSTM_english.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiLSTM_english_loss, BiLSTM_english_accuracy = BiLSTM_english.evaluate(val_input, val_output)\n",
    "print(f\"BiLSTM_english Loss: {BiLSTM_english_loss}, BiLSTM_english Accuracy: {BiLSTM_english_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bi-GRU-English**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 18s 106ms/step - loss: 0.6864 - accuracy: 0.5338 - val_loss: 0.6731 - val_accuracy: 0.5759\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 11s 97ms/step - loss: 0.5980 - accuracy: 0.7162 - val_loss: 0.7051 - val_accuracy: 0.5915\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 12s 109ms/step - loss: 0.4221 - accuracy: 0.8102 - val_loss: 0.8222 - val_accuracy: 0.5926\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 11s 93ms/step - loss: 0.2966 - accuracy: 0.8666 - val_loss: 0.9512 - val_accuracy: 0.5887\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 11s 100ms/step - loss: 0.2228 - accuracy: 0.9043 - val_loss: 1.1732 - val_accuracy: 0.5921\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 11s 97ms/step - loss: 0.1846 - accuracy: 0.9175 - val_loss: 1.3412 - val_accuracy: 0.5960\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 11s 95ms/step - loss: 0.1429 - accuracy: 0.9428 - val_loss: 1.5577 - val_accuracy: 0.5949\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 10s 90ms/step - loss: 0.1041 - accuracy: 0.9634 - val_loss: 1.7547 - val_accuracy: 0.5831\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 10s 90ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 1.7855 - val_accuracy: 0.5837\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 10s 88ms/step - loss: 0.0697 - accuracy: 0.9741 - val_loss: 2.0246 - val_accuracy: 0.5921\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.0246 - accuracy: 0.5921\n",
      "Validation Loss: 2.024561643600464, Validation Accuracy: 0.5920758843421936\n"
     ]
    }
   ],
   "source": [
    "# Build the BiGRU model\n",
    "input_shape = (2 * max_len,)\n",
    "embedding_dim = 64\n",
    "gru_units = 128\n",
    "\n",
    "BiGru_english = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_units)),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiGru_english.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiGru_english.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiGru_english_loss, BiGru_english_accuracy = BiGru_english.evaluate(val_input, val_output)\n",
    "print(f\"Validation Loss: {BiGru_english_loss}, Validation Accuracy: {BiGru_english_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 21ms/step\n",
      "20/20 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>BiLSTM_Predicted_Labels</th>\n",
       "      <th>BiGRU_Predicted_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "      <td>An emerging professional class.</td>\n",
       "      <td>Apologizing for losing your temper, even thoug...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stripe</td>\n",
       "      <td>N</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Businessmen of every stripe joined in oppositi...</td>\n",
       "      <td>They earned their stripes in Kuwait.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>check</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>As he called the role he put a check mark by e...</td>\n",
       "      <td>A check on its dependability under stress.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acquisition</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>The child's acquisition of language.</td>\n",
       "      <td>That graphite tennis racquet is quite an acqui...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thing</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>A thing of the spirit.</td>\n",
       "      <td>Things of the heart.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>sense</td>\n",
       "      <td>N</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>A keen musical sense.</td>\n",
       "      <td>A good sense of timing.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>rise</td>\n",
       "      <td>N</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>They asked for a 10% rise in rates.</td>\n",
       "      <td>The rising of the Holy Ghost.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>go</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>How did your interview go?</td>\n",
       "      <td>She was going that way anyway, so she offered ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>bull</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>He was a bull of a man.</td>\n",
       "      <td>He made a bad bull of the assignment.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>rise</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>Rise to the occasion.</td>\n",
       "      <td>Her spirits rose when she heard the good news.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column1 Column2  Column3  Column4  Column5  Column6  \\\n",
       "0          class       N       25       30       85       90   \n",
       "1         stripe       N       21       27       18       25   \n",
       "2          check       N       31       36        2        7   \n",
       "3    acquisition       N       12       23       41       52   \n",
       "4          thing       N        2        7        0        6   \n",
       "..           ...     ...      ...      ...      ...      ...   \n",
       "633        sense       N       15       20        7       12   \n",
       "634         rise       N       21       25        4       10   \n",
       "635           go       V       23       25        8       13   \n",
       "636         bull       N        9       13       14       18   \n",
       "637         rise       V        0        4       12       16   \n",
       "\n",
       "                                               Column7  \\\n",
       "0                      An emerging professional class.   \n",
       "1    Businessmen of every stripe joined in oppositi...   \n",
       "2    As he called the role he put a check mark by e...   \n",
       "3                 The child's acquisition of language.   \n",
       "4                               A thing of the spirit.   \n",
       "..                                                 ...   \n",
       "633                              A keen musical sense.   \n",
       "634                They asked for a 10% rise in rates.   \n",
       "635                         How did your interview go?   \n",
       "636                            He was a bull of a man.   \n",
       "637                              Rise to the occasion.   \n",
       "\n",
       "                                               Column8  \\\n",
       "0    Apologizing for losing your temper, even thoug...   \n",
       "1                 They earned their stripes in Kuwait.   \n",
       "2           A check on its dependability under stress.   \n",
       "3    That graphite tennis racquet is quite an acqui...   \n",
       "4                                 Things of the heart.   \n",
       "..                                                 ...   \n",
       "633                            A good sense of timing.   \n",
       "634                      The rising of the Holy Ghost.   \n",
       "635  She was going that way anyway, so she offered ...   \n",
       "636              He made a bad bull of the assignment.   \n",
       "637     Her spirits rose when she heard the good news.   \n",
       "\n",
       "     BiLSTM_Predicted_Labels  BiGRU_Predicted_Labels  \n",
       "0                          0                       0  \n",
       "1                          1                       0  \n",
       "2                          0                       0  \n",
       "3                          1                       1  \n",
       "4                          1                       1  \n",
       "..                       ...                     ...  \n",
       "633                        0                       0  \n",
       "634                        0                       1  \n",
       "635                        0                       0  \n",
       "636                        0                       0  \n",
       "637                        0                       0  \n",
       "\n",
       "[638 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"val.csv\")\n",
    "test_context1 = test_data[\"Column7\"].astype(str).tolist()\n",
    "test_context2 = test_data[\"Column8\"].astype(str).tolist()\n",
    "\n",
    "# Tokenize and preprocess the test data\n",
    "test_context1_seq = tokenizer.texts_to_sequences(test_context1)\n",
    "test_context2_seq = tokenizer.texts_to_sequences(test_context2)\n",
    "\n",
    "test_context1_seq = pad_sequences(test_context1_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "test_context2_seq = pad_sequences(test_context2_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "test_input = np.concatenate((test_context1_seq, test_context2_seq), axis=1)\n",
    "\n",
    "# Predict on the test data using the BiLSTM model\n",
    "BiLSTM_predictions = BiLSTM_english.predict(test_input)\n",
    "BiLSTM_predicted_labels = np.argmax(BiLSTM_predictions, axis=1)\n",
    "\n",
    "# Predict on the test data using the BiGRU model\n",
    "BiGRU_predictions = BiGru_english.predict(test_input)\n",
    "BiGRU_predicted_labels = np.argmax(BiGRU_predictions, axis=1)\n",
    "\n",
    "# Append predicted labels to the dataframe\n",
    "test_data[\"BiLSTM_Predicted_Labels\"] = BiLSTM_predicted_labels\n",
    "test_data[\"BiGRU_Predicted_Labels\"] = BiGRU_predicted_labels\n",
    "\n",
    "# Print the updated dataframe\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**German**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Starke</td>\n",
       "      <td>N</td>\n",
       "      <td>Herr Starke wollte uns kein Interview geben.</td>\n",
       "      <td>Das kann ich dir aber sagen: Wenn die Frau Sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benutzen</td>\n",
       "      <td>V</td>\n",
       "      <td>Meine Chefin benutzte ständig Fachbegriffe.</td>\n",
       "      <td>Auf dem Laptop benutze ich das Betriebssystem ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nepp</td>\n",
       "      <td>N</td>\n",
       "      <td>So muss sich Marion Drögsler, Vorstandsmitglie...</td>\n",
       "      <td>Verbraucherschützer warnen dennoch vor Nepp mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kapustin</td>\n",
       "      <td>N</td>\n",
       "      <td>Das kann ich dir aber sagen: Wenn die Frau Kap...</td>\n",
       "      <td>Kapustin kommt und geht.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schnapsbrennerin</td>\n",
       "      <td>N</td>\n",
       "      <td>Streuobstwiesenführerin, Hobbyimkerin, Schnaps...</td>\n",
       "      <td>Schnapsbrennerin Grete Wiederstein produziert ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47574</th>\n",
       "      <td>Staatsregierung</td>\n",
       "      <td>N</td>\n",
       "      <td>Die Staatsregierungen der einzelnen Bundesstaa...</td>\n",
       "      <td>Die Staatsregierungen der einzelnen Bundesstaa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47575</th>\n",
       "      <td>bedudeln</td>\n",
       "      <td>V</td>\n",
       "      <td>Und drittens: Camper, die am Elektrogrill ihre...</td>\n",
       "      <td>Geht aber trotzdem immer noch auf zwei Beinen,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47576</th>\n",
       "      <td>Marginalität</td>\n",
       "      <td>N</td>\n",
       "      <td>Das ist für viele Betroffene ein sehr hoher An...</td>\n",
       "      <td>Es kommt hier, wie zumeist, auf den konkreten ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47577</th>\n",
       "      <td>kennzeichnen</td>\n",
       "      <td>V</td>\n",
       "      <td>Wodurch kennzeichnen sich Meta-Suchmaschinen?</td>\n",
       "      <td>Neue Einträge sind besonders gekennzeichnet.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47578</th>\n",
       "      <td>tracken</td>\n",
       "      <td>V</td>\n",
       "      <td>Dass Cookies zum Tracken von Benutzern benutzt...</td>\n",
       "      <td>Es gibt Alternativen zum Tracken, beispielswei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47579 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column1 Column2  \\\n",
       "0                Starke       N   \n",
       "1              benutzen       V   \n",
       "2                  Nepp       N   \n",
       "3              Kapustin       N   \n",
       "4      Schnapsbrennerin       N   \n",
       "...                 ...     ...   \n",
       "47574   Staatsregierung       N   \n",
       "47575          bedudeln       V   \n",
       "47576      Marginalität       N   \n",
       "47577      kennzeichnen       V   \n",
       "47578           tracken       V   \n",
       "\n",
       "                                                 Column7  \\\n",
       "0           Herr Starke wollte uns kein Interview geben.   \n",
       "1            Meine Chefin benutzte ständig Fachbegriffe.   \n",
       "2      So muss sich Marion Drögsler, Vorstandsmitglie...   \n",
       "3      Das kann ich dir aber sagen: Wenn die Frau Kap...   \n",
       "4      Streuobstwiesenführerin, Hobbyimkerin, Schnaps...   \n",
       "...                                                  ...   \n",
       "47574  Die Staatsregierungen der einzelnen Bundesstaa...   \n",
       "47575  Und drittens: Camper, die am Elektrogrill ihre...   \n",
       "47576  Das ist für viele Betroffene ein sehr hoher An...   \n",
       "47577      Wodurch kennzeichnen sich Meta-Suchmaschinen?   \n",
       "47578  Dass Cookies zum Tracken von Benutzern benutzt...   \n",
       "\n",
       "                                                 Column8  Column9  \n",
       "0      Das kann ich dir aber sagen: Wenn die Frau Sta...        1  \n",
       "1      Auf dem Laptop benutze ich das Betriebssystem ...        1  \n",
       "2      Verbraucherschützer warnen dennoch vor Nepp mi...        1  \n",
       "3                               Kapustin kommt und geht.        1  \n",
       "4      Schnapsbrennerin Grete Wiederstein produziert ...        1  \n",
       "...                                                  ...      ...  \n",
       "47574  Die Staatsregierungen der einzelnen Bundesstaa...        0  \n",
       "47575  Geht aber trotzdem immer noch auf zwei Beinen,...        0  \n",
       "47576  Es kommt hier, wie zumeist, auf den konkreten ...        0  \n",
       "47577       Neue Einträge sind besonders gekennzeichnet.        0  \n",
       "47578  Es gibt Alternativen zum Tracken, beispielswei...        0  \n",
       "\n",
       "[47579 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"German.csv\")\n",
    "selected_columns = df2.iloc[:, [0, 1, 6, 7, 8]]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"German.csv\")\n",
    "\n",
    "# Extract the columns from the DataFrame\n",
    "train_word = df[\"Column1\"].tolist()\n",
    "train_context1 = df[\"Column7\"].astype(str).tolist()\n",
    "train_context2 = df[\"Column8\"].astype(str).tolist()\n",
    "train_label = np.array(df[\"Column9\"].tolist())\n",
    "\n",
    "# Prepare input and output data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_context1 + train_context2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_context1_seq = tokenizer.texts_to_sequences(train_context1)\n",
    "train_context2_seq = tokenizer.texts_to_sequences(train_context2)\n",
    "\n",
    "max_len = 30\n",
    "train_context1_seq = pad_sequences(train_context1_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "train_context2_seq = pad_sequences(train_context2_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "train_input = np.concatenate((train_context1_seq, train_context2_seq), axis=1)\n",
    "\n",
    "num_classes = 2\n",
    "train_output = tf.keras.utils.to_categorical(train_label, num_classes)\n",
    "\n",
    "# Train-validation split\n",
    "train_input, val_input, train_output, val_output = train_test_split(train_input, train_output, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiLstm-German**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "997/997 [==============================] - 214s 211ms/step - loss: 0.6472 - accuracy: 0.6222 - val_loss: 0.6247 - val_accuracy: 0.6525\n",
      "Epoch 2/10\n",
      "997/997 [==============================] - 202s 202ms/step - loss: 0.3569 - accuracy: 0.8472 - val_loss: 0.6922 - val_accuracy: 0.6618\n",
      "Epoch 3/10\n",
      "997/997 [==============================] - 202s 203ms/step - loss: 0.1070 - accuracy: 0.9605 - val_loss: 0.9047 - val_accuracy: 0.6588\n",
      "Epoch 4/10\n",
      "997/997 [==============================] - 205s 205ms/step - loss: 0.0476 - accuracy: 0.9839 - val_loss: 1.1596 - val_accuracy: 0.6568\n",
      "Epoch 5/10\n",
      "997/997 [==============================] - 205s 205ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 1.4127 - val_accuracy: 0.6520\n",
      "Epoch 6/10\n",
      "997/997 [==============================] - 214s 215ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.4549 - val_accuracy: 0.6501\n",
      "Epoch 7/10\n",
      "997/997 [==============================] - 215s 216ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 1.5541 - val_accuracy: 0.6613\n",
      "Epoch 8/10\n",
      "997/997 [==============================] - 208s 208ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.7344 - val_accuracy: 0.6442\n",
      "Epoch 9/10\n",
      "997/997 [==============================] - 207s 207ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.5489 - val_accuracy: 0.6449\n",
      "Epoch 10/10\n",
      "997/997 [==============================] - 207s 208ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.8767 - val_accuracy: 0.6514\n",
      "491/491 [==============================] - 20s 41ms/step - loss: 1.8767 - accuracy: 0.6514\n",
      "BiLSTM_german Loss  : 1.8767493963241577, BiLSTM_german Accuracy: 0.6513819694519043\n"
     ]
    }
   ],
   "source": [
    "# Build the BiLSTM model\n",
    "input_shape = (2 * max_len,)\n",
    "embedding_dim = 64\n",
    "lstm_units = 128\n",
    "\n",
    "BiLSTM_german = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units)),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiLSTM_german.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiLSTM_german.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiLSTM_german_loss, BiLSTM_german_accuracy = BiLSTM_german.evaluate(val_input, val_output)\n",
    "print(f\"BiLSTM_german Loss  : {BiLSTM_german_loss}, BiLSTM_german Accuracy: {BiLSTM_german_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiGru-German**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "997/997 [==============================] - 181s 177ms/step - loss: 0.6511 - accuracy: 0.6133 - val_loss: 0.6258 - val_accuracy: 0.6443\n",
      "Epoch 2/10\n",
      "997/997 [==============================] - 174s 174ms/step - loss: 0.3683 - accuracy: 0.8422 - val_loss: 0.7047 - val_accuracy: 0.6644\n",
      "Epoch 3/10\n",
      "997/997 [==============================] - 175s 175ms/step - loss: 0.1024 - accuracy: 0.9628 - val_loss: 0.8662 - val_accuracy: 0.6614\n",
      "Epoch 4/10\n",
      "997/997 [==============================] - 176s 176ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 1.0489 - val_accuracy: 0.6627\n",
      "Epoch 5/10\n",
      "997/997 [==============================] - 174s 174ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 1.3750 - val_accuracy: 0.6706\n",
      "Epoch 6/10\n",
      "997/997 [==============================] - 174s 175ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 1.5138 - val_accuracy: 0.6646\n",
      "Epoch 7/10\n",
      "997/997 [==============================] - 174s 174ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.4324 - val_accuracy: 0.6582\n",
      "Epoch 8/10\n",
      "997/997 [==============================] - 176s 176ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 1.5460 - val_accuracy: 0.6620\n",
      "Epoch 9/10\n",
      "997/997 [==============================] - 176s 176ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.6202 - val_accuracy: 0.6618\n",
      "Epoch 10/10\n",
      "997/997 [==============================] - 177s 178ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 1.6705 - val_accuracy: 0.6616\n",
      "491/491 [==============================] - 12s 25ms/step - loss: 1.6705 - accuracy: 0.6616\n",
      "BiGru_german_validation Loss: 1.6705224514007568,BiGru_german_validation Accuracy: 0.6615718007087708\n"
     ]
    }
   ],
   "source": [
    "# Build the BiGRU model\n",
    "input_shape = (2 * max_len,)\n",
    "embedding_dim = 64\n",
    "gru_units = 128\n",
    "\n",
    "BiGru_german = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_units)),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiGru_german.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiGru_german.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiGru_germa_loss, BiGru_germa_accuracy = BiGru_german.evaluate(val_input, val_output)\n",
    "print(f\"BiGru_german_validation Loss: {BiGru_germa_loss},BiGru_german_validation Accuracy: {BiGru_germa_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**French**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ShuoWen</td>\n",
       "      <td>N</td>\n",
       "      <td>Comme l'indique le Shuowen Jiezi (dans son com...</td>\n",
       "      <td>D’après le dictionnaire étymologique shuowen, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amélioration</td>\n",
       "      <td>N</td>\n",
       "      <td>L’éclaircie est généralement une coupe d’améli...</td>\n",
       "      <td>Améliorations utiles.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dessinateur</td>\n",
       "      <td>N</td>\n",
       "      <td>Un dessinateur de jardins.</td>\n",
       "      <td>Un dessinateur de machines.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oïdium</td>\n",
       "      <td>N</td>\n",
       "      <td>On projette de la fleur de soufre sur les vign...</td>\n",
       "      <td>Le fénarimol est un fongicide largement utilis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>redétendre</td>\n",
       "      <td>V</td>\n",
       "      <td>Afin d’économiser le gaz dans le circuit, celu...</td>\n",
       "      <td>Malgré la colère qui montait, il a pu redétend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39169</th>\n",
       "      <td>acoustique</td>\n",
       "      <td>N</td>\n",
       "      <td>Ce sont des lieux dont l’acoustique est belle,...</td>\n",
       "      <td>Traité d’acoustique.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39170</th>\n",
       "      <td>ordonnancer</td>\n",
       "      <td>V</td>\n",
       "      <td>C’était Margellin, sûrement, qui avait ordonna...</td>\n",
       "      <td>Ordonnancer un mémoire.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39171</th>\n",
       "      <td>koko</td>\n",
       "      <td>V</td>\n",
       "      <td>Quelques pincées de koko sont ajoutées en fin ...</td>\n",
       "      <td>Le koko peut aussi être planté, autour des vil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39172</th>\n",
       "      <td>pistard</td>\n",
       "      <td>N</td>\n",
       "      <td>Ces « pistards » impénitents ont érigé la pist...</td>\n",
       "      <td>Ce pistard sprinteur, roi du tartan, s’est pri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39173</th>\n",
       "      <td>parlote</td>\n",
       "      <td>N</td>\n",
       "      <td>Il revient et finalement , après des parlotes ...</td>\n",
       "      <td>C’est l’heure où les retardataires viennent je...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39174 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column1 Column2  \\\n",
       "0           ShuoWen       N   \n",
       "1      amélioration       N   \n",
       "2       dessinateur       N   \n",
       "3            oïdium       N   \n",
       "4        redétendre       V   \n",
       "...             ...     ...   \n",
       "39169    acoustique       N   \n",
       "39170   ordonnancer       V   \n",
       "39171          koko       V   \n",
       "39172       pistard       N   \n",
       "39173       parlote       N   \n",
       "\n",
       "                                                 Column7  \\\n",
       "0      Comme l'indique le Shuowen Jiezi (dans son com...   \n",
       "1      L’éclaircie est généralement une coupe d’améli...   \n",
       "2                             Un dessinateur de jardins.   \n",
       "3      On projette de la fleur de soufre sur les vign...   \n",
       "4      Afin d’économiser le gaz dans le circuit, celu...   \n",
       "...                                                  ...   \n",
       "39169  Ce sont des lieux dont l’acoustique est belle,...   \n",
       "39170  C’était Margellin, sûrement, qui avait ordonna...   \n",
       "39171  Quelques pincées de koko sont ajoutées en fin ...   \n",
       "39172  Ces « pistards » impénitents ont érigé la pist...   \n",
       "39173  Il revient et finalement , après des parlotes ...   \n",
       "\n",
       "                                                 Column8  Column9  \n",
       "0      D’après le dictionnaire étymologique shuowen, ...        1  \n",
       "1                                  Améliorations utiles.        1  \n",
       "2                            Un dessinateur de machines.        1  \n",
       "3      Le fénarimol est un fongicide largement utilis...        1  \n",
       "4      Malgré la colère qui montait, il a pu redétend...        1  \n",
       "...                                                  ...      ...  \n",
       "39169                               Traité d’acoustique.        0  \n",
       "39170                            Ordonnancer un mémoire.        0  \n",
       "39171  Le koko peut aussi être planté, autour des vil...        0  \n",
       "39172  Ce pistard sprinteur, roi du tartan, s’est pri...        0  \n",
       "39173  C’est l’heure où les retardataires viennent je...        0  \n",
       "\n",
       "[39174 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"French.csv\")\n",
    "selected_columns = df3.iloc[:, [0, 1, 6, 7, 8]]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"French.csv\")\n",
    "\n",
    "# Extract the columns from the DataFrame\n",
    "train_word = df[\"Column1\"].tolist()\n",
    "train_context1 = df[\"Column7\"].astype(str).tolist()\n",
    "train_context2 = df[\"Column8\"].astype(str).tolist()\n",
    "train_label = np.array(df[\"Column9\"].tolist())\n",
    "\n",
    "# Prepare input and output data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_context1 + train_context2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_context1_seq = tokenizer.texts_to_sequences(train_context1)\n",
    "train_context2_seq = tokenizer.texts_to_sequences(train_context2)\n",
    "\n",
    "max_len = 30\n",
    "train_context1_seq = pad_sequences(train_context1_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "train_context2_seq = pad_sequences(train_context2_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "train_input = np.concatenate((train_context1_seq, train_context2_seq), axis=1)\n",
    "\n",
    "num_classes = 2\n",
    "train_output = tf.keras.utils.to_categorical(train_label, num_classes)\n",
    "\n",
    "# Train-validation split\n",
    "train_input, val_input, train_output, val_output = train_test_split(train_input, train_output, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiLstm-French**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "821/821 [==============================] - 172s 199ms/step - loss: 0.6846 - accuracy: 0.5501 - val_loss: 0.6834 - val_accuracy: 0.5601\n",
      "Epoch 2/10\n",
      "821/821 [==============================] - 161s 196ms/step - loss: 0.4595 - accuracy: 0.7883 - val_loss: 0.7723 - val_accuracy: 0.5838\n",
      "Epoch 3/10\n",
      "821/821 [==============================] - 162s 197ms/step - loss: 0.1502 - accuracy: 0.9406 - val_loss: 0.9873 - val_accuracy: 0.5817\n",
      "Epoch 4/10\n",
      "821/821 [==============================] - 161s 196ms/step - loss: 0.0602 - accuracy: 0.9777 - val_loss: 1.3569 - val_accuracy: 0.5821\n",
      "Epoch 5/10\n",
      "821/821 [==============================] - 162s 197ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 1.7937 - val_accuracy: 0.5866\n",
      "Epoch 6/10\n",
      "821/821 [==============================] - 162s 197ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 2.1158 - val_accuracy: 0.5848\n",
      "Epoch 7/10\n",
      "821/821 [==============================] - 163s 198ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 2.1456 - val_accuracy: 0.5914\n",
      "Epoch 8/10\n",
      "821/821 [==============================] - 162s 198ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 2.1376 - val_accuracy: 0.5918\n",
      "Epoch 9/10\n",
      "821/821 [==============================] - 163s 199ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 2.4065 - val_accuracy: 0.5820\n",
      "Epoch 10/10\n",
      "821/821 [==============================] - 160s 195ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 2.3284 - val_accuracy: 0.5814\n",
      "404/404 [==============================] - 16s 41ms/step - loss: 2.3284 - accuracy: 0.5814\n",
      "BiLSTM_french Loss  : 2.328373670578003, BiLSTM_french Accuracy: 0.5813737511634827\n"
     ]
    }
   ],
   "source": [
    "# Build the BiLSTM model\n",
    "input_shape = (2 * max_len,)\n",
    "embedding_dim = 64\n",
    "lstm_units = 128\n",
    "\n",
    "BiLSTM_french = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units)),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiLSTM_french.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiLSTM_french.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiLSTM_french_loss, BiLSTM_french_accuracy = BiLSTM_french.evaluate(val_input, val_output)\n",
    "print(f\"BiLSTM_french Loss  : {BiLSTM_french_loss}, BiLSTM_french Accuracy: {BiLSTM_french_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiGRU-French**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "821/821 [==============================] - 151s 174ms/step - loss: 0.6849 - accuracy: 0.5417 - val_loss: 0.6792 - val_accuracy: 0.5565\n",
      "Epoch 2/10\n",
      "821/821 [==============================] - 145s 177ms/step - loss: 0.4807 - accuracy: 0.7746 - val_loss: 0.7603 - val_accuracy: 0.5746\n",
      "Epoch 3/10\n",
      "821/821 [==============================] - 124s 151ms/step - loss: 0.1769 - accuracy: 0.9310 - val_loss: 1.0270 - val_accuracy: 0.5803\n",
      "Epoch 4/10\n",
      "821/821 [==============================] - 141s 172ms/step - loss: 0.0703 - accuracy: 0.9753 - val_loss: 1.4074 - val_accuracy: 0.5811\n",
      "Epoch 5/10\n",
      "821/821 [==============================] - 139s 170ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 1.9299 - val_accuracy: 0.5844\n",
      "Epoch 6/10\n",
      "821/821 [==============================] - 143s 174ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 2.0365 - val_accuracy: 0.5807\n",
      "Epoch 7/10\n",
      "821/821 [==============================] - 144s 176ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 2.4387 - val_accuracy: 0.5857\n",
      "Epoch 8/10\n",
      "821/821 [==============================] - 141s 172ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 2.5875 - val_accuracy: 0.5823\n",
      "Epoch 9/10\n",
      "821/821 [==============================] - 171s 209ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 2.5658 - val_accuracy: 0.5815\n",
      "Epoch 10/10\n",
      "821/821 [==============================] - 130s 158ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 2.8514 - val_accuracy: 0.5815\n",
      "404/404 [==============================] - 9s 21ms/step - loss: 2.8514 - accuracy: 0.5815\n",
      "BiGru_french_validation Loss: 2.8514299392700195,BiGru_french_validation Accuracy: 0.5814511179924011\n"
     ]
    }
   ],
   "source": [
    "# Build the BiGRU model\n",
    "input_shape = (2 * max_len,)\n",
    "embedding_dim = 64\n",
    "gru_units = 128\n",
    "\n",
    "BiGru_french = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_shape=input_shape),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_units)),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "BiGru_french.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "BiGru_french.fit(train_input, train_output, validation_data=(val_input, val_output), batch_size=32, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "BiGru_french_loss, BiGru_french_accuracy = BiGru_french.evaluate(val_input, val_output)\n",
    "print(f\"BiGru_french_validation Loss: {BiGru_french_loss},BiGru_french_validation Accuracy: {BiGru_french_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>BiLSTM Accuracy</th>\n",
       "      <th>BiGRU Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>0.577009</td>\n",
       "      <td>0.573103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>0.583308</td>\n",
       "      <td>0.572633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>0.651382</td>\n",
       "      <td>0.661572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language  BiLSTM Accuracy  BiGRU Accuracy\n",
       "0  English         0.577009        0.573103\n",
       "1   French         0.583308        0.572633\n",
       "2   German         0.651382        0.661572"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "languages = [\"English\", \"French\", \"German\"]\n",
    "bilstm_acc = [BiLSTM_english_accuracy, BiLSTM_french_accuracy, BiLSTM_german_accuracy]\n",
    "bigru_acc = [BiGru_english_accuracy, BiGru_french_accuracy, BiGru_germa_accuracy]\n",
    "df = pd.DataFrame({\"Language\": languages, \"BiLSTM Accuracy\": bilstm_acc, \"BiGRU Accuracy\": bigru_acc})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the accuracies for each language and model\n",
    "languages = [\"English\", \"French\", \"German\"]\n",
    "bilstm_acc = [BiLSTM_english_accuracy, BiLSTM_french_accuracy, BiLSTM_german_accuracy]\n",
    "bigru_acc = [BiGru_english_accuracy, BiGru_french_accuracy, BiGru_germa_accuracy]\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot the BiLSTM and BiGRU accuracies as two lines\n",
    "ax.plot(languages, bilstm_acc, label=\"BiLSTM\")\n",
    "ax.plot(languages, bigru_acc, label=\"BiGRU\")\n",
    "\n",
    "# Add labels and a legend\n",
    "ax.set_xlabel(\"Language\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy comparison of BiLSTM and BiGRU models\")\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylim([0.56, 0.67])\n",
    "ax.set_yticks([0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67])\n",
    "\n",
    "for i, acc in enumerate(bilstm_acc):\n",
    "    ax.text(languages[i], acc, f\"{acc:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "for i, acc in enumerate(bigru_acc):\n",
    "    ax.text(languages[i], acc, f\"{acc:.2f}\", ha=\"center\", va=\"top\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695/695 [==============================] - 16s 24ms/step\n",
      "695/695 [==============================] - 13s 19ms/step\n",
      "BiLSTM Predicted Labels:\n",
      "[0 1 0 ... 0 0 1]\n",
      "BiGRU Predicted Labels:\n",
      "[0 1 0 ... 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>BiLSTM_Predicted_Labels</th>\n",
       "      <th>BiGRU_Predicted_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>palpe</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Palpes maxillaires et palpes labiales.</td>\n",
       "      <td>Les palpes d’un hanneton.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paravent</td>\n",
       "      <td>N</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Se servir de quelqu’un comme paravent.</td>\n",
       "      <td>Paravent chinois. — Paravent d’étoffe, de tapi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attirer</td>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>L’aimant a la vertu d’attirer le fer.</td>\n",
       "      <td>L’ambre frotté attire les corps légers non mét...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>débat</td>\n",
       "      <td>N</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>La réal-politique peut donc, par cet exécutoir...</td>\n",
       "      <td>Ouvrir, fermer les débats. — La clôture des dé...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>règle</td>\n",
       "      <td>N</td>\n",
       "      <td>113</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Il offre des sacrifices, aux autres dieux selo...</td>\n",
       "      <td>Suivre la règle. — Se conformer à la règle.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22227</th>\n",
       "      <td>errer</td>\n",
       "      <td>V</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>Il n’y a personne qui ne puisse errer, qui ne ...</td>\n",
       "      <td>Si je me trompe, laissez-moi errer.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22228</th>\n",
       "      <td>aimer</td>\n",
       "      <td>V</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>Deux personnes qui s’aiment tendrement.</td>\n",
       "      <td>Le temps d’aimer.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22229</th>\n",
       "      <td>poldériser</td>\n",
       "      <td>V</td>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>Le tableau suivant fournit le détail des dépen...</td>\n",
       "      <td>Au XIe siècle, on a commencé à endiguer et pol...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22230</th>\n",
       "      <td>transnosographie</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Transnosographie du syndrome S.</td>\n",
       "      <td>Transnosographie, la crise suicidaire (le fait...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22231</th>\n",
       "      <td>séduire</td>\n",
       "      <td>V</td>\n",
       "      <td>103</td>\n",
       "      <td>110</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>Privé de tout accommodement, de ses fards, de ...</td>\n",
       "      <td>Le faux espoir qui nous avait séduits.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22232 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column1 Column2  Column3  Column4  Column5  Column6  \\\n",
       "0                 palpe       N        0        6        4       10   \n",
       "1              paravent       N       29       37        0        8   \n",
       "2               attirer       V       22       29       15       21   \n",
       "3                 débat       N       75       80       19       25   \n",
       "4                 règle       N      113      118       10       15   \n",
       "...                 ...     ...      ...      ...      ...      ...   \n",
       "22227             errer       V       32       37       29       34   \n",
       "22228             aimer       V       21       27       11       16   \n",
       "22229        poldériser       V       89       99       43       53   \n",
       "22230  transnosographie       N        0       16        0       16   \n",
       "22231           séduire       V      103      110       30       37   \n",
       "\n",
       "                                                 Column7  \\\n",
       "0                 Palpes maxillaires et palpes labiales.   \n",
       "1                 Se servir de quelqu’un comme paravent.   \n",
       "2                  L’aimant a la vertu d’attirer le fer.   \n",
       "3      La réal-politique peut donc, par cet exécutoir...   \n",
       "4      Il offre des sacrifices, aux autres dieux selo...   \n",
       "...                                                  ...   \n",
       "22227  Il n’y a personne qui ne puisse errer, qui ne ...   \n",
       "22228            Deux personnes qui s’aiment tendrement.   \n",
       "22229  Le tableau suivant fournit le détail des dépen...   \n",
       "22230                    Transnosographie du syndrome S.   \n",
       "22231  Privé de tout accommodement, de ses fards, de ...   \n",
       "\n",
       "                                                 Column8  \\\n",
       "0                              Les palpes d’un hanneton.   \n",
       "1      Paravent chinois. — Paravent d’étoffe, de tapi...   \n",
       "2      L’ambre frotté attire les corps légers non mét...   \n",
       "3      Ouvrir, fermer les débats. — La clôture des dé...   \n",
       "4            Suivre la règle. — Se conformer à la règle.   \n",
       "...                                                  ...   \n",
       "22227                Si je me trompe, laissez-moi errer.   \n",
       "22228                                  Le temps d’aimer.   \n",
       "22229  Au XIe siècle, on a commencé à endiguer et pol...   \n",
       "22230  Transnosographie, la crise suicidaire (le fait...   \n",
       "22231             Le faux espoir qui nous avait séduits.   \n",
       "\n",
       "       BiLSTM_Predicted_Labels  BiGRU_Predicted_Labels  \n",
       "0                            0                       0  \n",
       "1                            1                       1  \n",
       "2                            0                       0  \n",
       "3                            0                       0  \n",
       "4                            0                       0  \n",
       "...                        ...                     ...  \n",
       "22227                        0                       0  \n",
       "22228                        0                       0  \n",
       "22229                        0                       0  \n",
       "22230                        0                       0  \n",
       "22231                        1                       1  \n",
       "\n",
       "[22232 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data = pd.read_csv(\"French test.csv\")\n",
    "test_context1 = test_data[\"Column7\"].astype(str).tolist()\n",
    "test_context2 = test_data[\"Column8\"].astype(str).tolist()\n",
    "\n",
    "\n",
    "test_context1_seq = tokenizer.texts_to_sequences(test_context1)\n",
    "test_context2_seq = tokenizer.texts_to_sequences(test_context2)\n",
    "\n",
    "test_context1_seq = pad_sequences(test_context1_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "test_context2_seq = pad_sequences(test_context2_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "test_input = np.concatenate((test_context1_seq, test_context2_seq), axis=1)\n",
    "\n",
    "\n",
    "BiLSTM_predictions = BiLSTM_french.predict(test_input)\n",
    "BiLSTM_predicted_labels = np.argmax(BiLSTM_predictions, axis=1)\n",
    "\n",
    "\n",
    "BiGRU_predictions = BiGru_french.predict(test_input)\n",
    "BiGRU_predicted_labels = np.argmax(BiGRU_predictions, axis=1)\n",
    "\n",
    "test_data[\"BiLSTM_Predicted_Labels\"] = BiLSTM_predicted_labels\n",
    "test_data[\"BiGRU_Predicted_Labels\"] = BiGRU_predicted_labels\n",
    "\n",
    "\n",
    "print(\"BiLSTM Predicted Labels:\")\n",
    "print(BiLSTM_predicted_labels)\n",
    "\n",
    "print(\"BiGRU Predicted Labels:\")\n",
    "print(BiGRU_predicted_labels)\n",
    "\n",
    "test_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
